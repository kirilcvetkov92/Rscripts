\documentclass{beamer}
\usetheme{Madrid}
\usepackage{mathtools,amsmath}
\usepackage{subfig}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning}
\pdfmapfile{+sansmathaccent.map}

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------
\title[decision trees and noisy labels]{%
Decision trees and ways on removing noisy labels\\
  \large Identify costumers in unsound service models}
% The short title appears at the bottom of every slide, the full title is only on the title page

\author{Yannick Misteli} % Your name
\institute[Julius B{\"a}r] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Julius B{\"a}r \\ % Your institution for the title page
\medskip
\textit{yannick.misteli@juliusbaer.com} % Your email address
}
\date{\today} % Date, can be changed to a custom date


\begin{document}


%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------
\begin{frame}[fragile]
\titlepage % Print the title page as the first slide
<<setup, include=FALSE>>=
library(knitr)
library(caret)
library(GGally)
library(foreach)
library(scales)
library(rattle)
set.seed(1234)
clean_data <- read.csv("../clean_data.csv")
clean_data$X <- NULL
options(width = 150)
  labelnoise <- 20
  len <- nrow(clean_data)
  noisy_data <- clean_data
  resample <- sample.int(len, len/100*labelnoise)
  mylabels <- unique(clean_data$Service.Model)
  for(k in resample){
    myset <- noisy_data[k,]
    noisy_data[k,1] <- sample(mylabels[!(myset$Service.Model == mylabels)],1)
  }
data <- noisy_data  
@


\end{frame}
%------------------------------------------------
\begin{frame}[fragile]
\frametitle{Overview} % Table of contents slide, comment this block out to remove it
\tableofcontents[hideallsubsections] % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}
%------------------------------------------------
\section{Interpretable Models and general aspects of ML} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------


\subsection{Introduction} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks
%------------------------------------------------
\begin{frame}[fragile]
\frametitle{Introduction}
% Define block styles
%\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
 %   text width=4.5em, text badly centered, node distance=1.5cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!50, 
    text width=4em, text centered, rounded corners, minimum height=2em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse,fill=blue!20, node distance=2cm,
    minimum height=2em]
\begin{minipage}[c]{.5\textwidth} % Left column and width
\begin{figure}
\textbf{Traditional Programming}\par\medskip
\begin{tikzpicture}[auto]
    % Place nodes
    \node [block] (comp) {Computer};
    \node [cloud, above left of = comp] (data) {Data};
    \node [cloud, above right of=comp] (rules) {Rules};   
    \node [cloud, below of=comp] (output) {Output};
    % Draw edges
    \path [line] (rules) -- (comp);
    \path [line] (data) -- (comp);
    \path [line] (comp) -- (output);
\end{tikzpicture}
%\caption{Business Rules are used together with data to produce output}
\end{figure}
\end{minipage}%
\begin{minipage}[c]{.5\textwidth} % Left column and width
\begin{figure}
\textbf{Supervised Machine Learning}\par\medskip
\begin{tikzpicture}[auto]
    % Place nodes
    \node [block] (comp) {Computer};
    \node [cloud, above left of = comp] (data) {Data};
    \node [cloud, above right of=comp] (output) {Output};   
    \node [cloud, below of=comp] (rules) {Rules};
    % Draw edges
    \path [line] (output) -- (comp);
    \path [line] (data) -- (comp);
    \path [line] (comp) -- (rules);
\end{tikzpicture}
%\caption{The output together with the data is used to deduce business rules.}
\end{figure}
\end{minipage}
\end{frame}

%------------------------------------------------
%
\subsection{Interpretability} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks

%------------------------------------------------
\begin{frame}[fragile]
\frametitle{Interpretability\footnotemark[1]}
\begin{block}{Interpretability}
Interpretability is the degree to which a human can understand the cause of a decision\footnotemark[2]
\end{block}
\begin{itemize}
\item The importance of interpretability (Regulator) or \textbf{what vs why and finding meaning in the world}
\item Criteria for interpretability methods or \textbf{intrinsic vs post hoc}
\item Human-friendly explanations or \textbf{what is a good explanation?}
\end{itemize}
\footnotetext[1]{Molnar, Christoph. 2018., "Interpretable Machine Learning", Leanpub}
\footnotetext[2]{Miller, Tim. 2017. "Explanation in Artificial Intelligence: Insights from the Social Sciences." arXiv Preprint arXiv:1706.07269}
\end{frame}
%------------------------------------------------
\subsection{Interpretable Models} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks
%------------------------------------------------
\begin{frame}[fragile]
\frametitle{Interpretable Models}
\begin{columns}[c] % The "c" option specifies centered vertical alignment while the "t" option is used for top vertical alignment
\column{.35\textwidth} % Left column and width
\begin{block}{Models}
\begin{itemize}
\item Linear models 
\item Logistic regression 
\item Naive Bayes
\item \textbf{Decision trees} 
\item RuleFit\footnotemark[3]
\item k-Nearest Neighbours
\end{itemize}
\end{block}
\column{.65\textwidth} % Left column and width
\tiny
\begin{itemize}
\item[] \begin{equation*}\begin{aligned} y_i &= \beta_0 + \beta_1 x_{i,1} + \ldots + \beta_p x_{i,p} + \epsilon_i \\
P(y_i = 1) &= \frac{1}{1+exp(-(\beta_0+\beta_1 x_{i,1} + \ldots + \beta_p x_{i,p}))} \\
P(C_k \mid x) &= \frac{1}{Z} P(C_k) \prod_{i=1}^n P(x_i \mid C_k)\end{aligned}\end{equation*}
\item[] 
\begin{figure}
	\includegraphics[width=0.5\linewidth]{tree_example.png}
\end{figure}
\item[] 
\begin{figure}
	\includegraphics[width=0.6\linewidth]{rulefit.png}
\end{figure}
\item[] \begin{figure}
	\includegraphics[width=0.15\linewidth]{knn.png}
\end{figure}
\end{itemize}
\end{columns}
\footnotetext[3]{Friedman-Popescu, Tech Rep, Stat. Dpt, Standford U., 2003}
\end{frame}
%------------------------------------------------
\section{Use Case} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks
\subsection{Service Models}
%------------------------------------------------
\begin{frame}[fragile]
\frametitle{Service Models}
\begin{columns}[c] % The "c" option specifies centered vertical alignment while the "t" option is used for top vertical alignment

\column{.45\textwidth} % Left column and width


\textbf{Advisory Service Models}
\begin{enumerate}
\item Basic
\item Premium
\item Advanced
\end{enumerate}

Every advised client signs a service model agreement. Hence, according to preferences and service needs either a basic, premium or advanced service contract is put in place. 

\column{.5\textwidth} % Right column and width

\begin{figure}
	\includegraphics[width=\linewidth]{service_model.png}
\end{figure}

\end{columns}

\begin{figure}
	\includegraphics[width=0.5\linewidth]{swisscom.png}
\end{figure}

\end{frame}

\subsection{Use case}
%------------------------------------------------
\begin{frame}[fragile]
\frametitle{Use case}
\begin{columns}[c] % The "c" option specifies centered vertical alignment while the "t" option is used for top vertical alignment
\column{.45\textwidth} % Left column and width
\begin{block}{Problem}
How to identify clients that should be in a different Service Model?
\end{block}
\begin{block}{Idea}
Fit decision tree and investigate terminal nodes for misclassified clients
\end{block}
\begin{block}{Intention}
Up- and downselling of misclassified clients
\end{block}
\column{.5\textwidth} % Right column and width
\begin{figure}
	\includegraphics[width=\linewidth]{tree_plot.jpg}
\end{figure}
\end{columns}
\end{frame}

\subsection{Dataset}
%------------------------------------------------
\begin{frame}[fragile]
\frametitle{Dataset}
\small
\begin{columns}[c] % The "c" option specifies centered vertical alignment while the "t" option is used for top vertical alignment
\column{.6\textwidth} % Left column and width
\centering
\begin{block}{Generating multivariate tri-modal mixed distributions}
Multivariate data with count and continuous variable with a pre-specified correlation matrix is generated. The count and continouous variable are assumed to have Poisson and normal marginals, respectively. The resulting mixture is
\centering
\begin{equation*}
F(x) =  \sum_{i=1}^{n}  w_i P_i(x),
\end{equation*}
where $n = 3;w_1 = 0.6, w_2 = 0.3, w_3 = 0.1$ and $P_i$ is the corresponding multivariate Poisson-Normal distribution.
\end{block}
\column{.35\textwidth} % Right column and width
\centering
\begin{figure}
	\includegraphics[width=0.75\linewidth]{multivariate_normal_sample.png}
	\caption{\small Example of sample points from a multivariate normal distribution with $\sigma = \begin{bsmallmatrix} 0 \\ 0 \end{bsmallmatrix}$ and $\Sigma = \begin{bsmallmatrix}1 & \frac{3}{5}\\ \frac{3}{5} & 2\end{bsmallmatrix}$, shown along with the 3-sigma ellipse.\footnotemark[4]}
\end{figure}
\end{columns}
\footnotetext[4]{en.wikipedia.org/wiki/Multivariate\_normal\_distribution}
\end{frame}
%------------------------------------------------
\begin{frame}[fragile]{Data Summary}

\tiny
{\setbeamercolor{block title}{bg=red!75}
\begin{block}{\tiny Synthetic Data}
All data contained in these slides have been generated synthetically and not by Julius B\"{a}r. In no event shall the author or Julius B\"{a}r be liable for any direct, indirect, special or incidental damages resulting from, arising out of or in connection with, the use of the data contained herein.
\end{block}
}
\begin{minipage}[t]{0.45\textwidth}
  \vspace{0pt}
<<echo=FALSE>>=
options(width = 50)
@
  
<<>>=
head(data)
@
\end{minipage}
\hfill
\begin{minipage}[t]{0.45\textwidth}
  \vspace{0pt}
<<>>=
summary(data[,1:6])
@
\end{minipage}
\end{frame}
%------------------------------------------------
\begin{frame}[fragile]{Exploratory Data Analysis}
\tiny
<<echo=FALSE>>=
partition <- createDataPartition(data$Service.Model, p = 0.01, list = FALSE)
plt_data <- data[partition,]
# ggpairs(plt_data[,1:6], aes(color  = Service.Model))
# p_ <- GGally::print_if_interactive
@
{\setbeamercolor{block title}{bg=red!75}
\begin{block}{\tiny Synthetic Data}
All data contained in these slides have been generated synthetically and not by Julius B\"{a}r. In no event shall the author or Julius B\"{a}r be liable for any direct, indirect, special or incidental damages resulting from, arising out of or in connection with, the use of the data contained herein.
\end{block}
}
<<plots_ggpairs, fig.width=8,fig.height=4,out.width='\\linewidth',results='hold',echo=FALSE, message=FALSE>>=
#ggpairs(plt_data[,1:6], aes(color = Service.Model),lower=list(combo = wrap("facethist",binwidth = 1)))
ggpairs(plt_data[,1:6], aes(color = Service.Model))
@

<<plots_rpart, fig.width=8,fig.height=4,out.width='\\linewidth',results='hold',echo=FALSE, message=FALSE,warning=FALSE>>=
# trainCall <- function(i){
#   tunelen <- 20
#   cat("----------------------------------------------------","\n");
#   set.seed(123); cat(i," <- loaded\n");
# 
#   control <- trainControl(method="repeatedcv",
#                          number=10, repeats = 10,
#                          verboseIter = FALSE
#                          )
#   t2 <- train(y=Y, x=X, (i), trControl = control, tuneLength = tunelen)
# }
# X <- data[,-1]
# Y <- data[,1]
# tree <- trainCall("rpart2")
# fancyRpartPlot(tree$finalModel)
@
\end{frame}
%------------------------------------------------
\begin{frame}[fragile]{Label Noise}
\tiny
{\setbeamercolor{block title}{bg=red!75}
\begin{block}{\tiny Synthetic Data}
All data contained in these slides have been generated synthetically and not by Julius B\"{a}r. In no event shall the author or Julius B\"{a}r be liable for any direct, indirect, special or incidental damages resulting from, arising out of or in connection with, the use of the data contained herein.
\end{block}
}
<<noisy_data,out.width='\\linewidth',results='hide',echo=TRUE, message=FALSE, eval=FALSE>>=
  noisy_data <- clean_data
  leng <- nrow(noisy_data)
  labelnoise <- 20
  resample <- sample.int(leng, leng/100*labelnoise)
  mylabels <- unique(clean_data$Service.Model)
  for(k in resample){
    myset <- noisy_data[k,]
    noisy_data[k,1] <- sample(mylabels[(myset$Service.Model != mylabels)],1)
  }
@
\end{frame}
\subsection{Decision tree}
%------------------------------------------------
\begin{frame}[fragile]{Decision Tree}
\tiny
<<tree_calc, echo=FALSE, message=FALSE, warning=FALSE,results='hide'>>=
  X = data[,-1]
  Y = data[,1]
  tunelen <- 20
  control <- trainControl(method="repeatedcv",
                         number=10, repeats = 10,
                         verboseIter = TRUE
                         )
  tree <- train(y=Y,x=X, "rpart2", trControl = control, tuneLength = tunelen)
@
{\setbeamercolor{block title}{bg=red!75}
\begin{block}{\tiny Synthetic Data}
All data contained in these slides have been generated synthetically and not by Julius B\"{a}r. In no event shall the author or Julius B\"{a}r be liable for any direct, indirect, special or incidental damages resulting from, arising out of or in connection with, the use of the data contained herein.
\end{block}
}
<<plots_tree, fig.width=8,fig.height=4,out.width='\\linewidth',results='hold',echo=FALSE, message=FALSE>>=
fancyRpartPlot(tree$finalModel)
@

\end{frame}

\section{After Math}

\subsection{Noisy Labels}
%------------------------------------------------
\begin{frame}[fragile]{Noisy lables - sources and effects\footnotemark[5]}
\small
\begin{minipage}[c]{0.6\textwidth}
\begin{block}{\small Sources of noise}
\begin{itemize}
\item insufficient information provided to the expert
\item errors in the expert labelling itself
\item subjectivity of the labelling task
\item communication/enconding problems
\end{itemize}
\end{block}
\begin{block}{\small Effects of noise}
\begin{itemize}
\item decrease the classification performances
\item increase/decrease the complexity of learned models
\item pose a threat to tasks like e.g. feature selection
\end{itemize}
\end{block}
\end{minipage}%
\begin{minipage}[c]{0.4\textwidth}
\begin{figure}%
    \centering
    \subfloat{{\includegraphics[width=0.3\textwidth]{labels.png} }}%
    \qquad
    \subfloat{{\includegraphics[width=0.3\textwidth]{xray.jpg} }}%
    %\caption{2 Figures side by side}%
    %\label{fig:example}%
\end{figure}
\begin{figure}
	\includegraphics[width=0.75\linewidth]{cat_dog.png}
\end{figure}
\end{minipage}
\footnotetext[5]{\tiny https://labelnoise2017.loria.fr/wp-content/uploads/2017/11/présentation-LABELNOISE17-Frénay.pdf}
\end{frame}

\subsection{Dealing with Noise}
%------------------------------------------------
\begin{frame}[fragile]{Dealing with Noise}
\begin{columns}[c] % The "c" option specifies centered vertical alignment while the "t" option is used for top vertical alignment
\column{.4\textwidth} % Left column and width
\small
\begin{block}{\small Dealing with Noise}
\begin{itemize}
\item overfitting avoidance and robust losses
\item data cleansing
\item noise-tolerant algorithms
\end{itemize}
\end{block}
\begin{figure}
	\includegraphics[width=\linewidth]{NoiseFiltersR.png}
\end{figure}
\column{.5\textwidth} % right column and width
\tiny
<<remove_noise,out.width='\\textwidth'>>=
library(NoiseFiltersR)
out <- C45robustFilter(Service.Model ~.,data = data) 
cldata <- out$cleanData
print(out)
@
\end{columns}
\end{frame}

\subsection{Noise Sensitivity of ML algorithms}
%------------------------------------------------
\begin{frame}[fragile]{Noise Sensitivity of ML algorithms (preliminary results)}
\tiny
<<results='hide',echo=FALSE>>=
all_results <- read.csv("../result_new.csv")
all_results$X <- NULL
final_plot <- ggplot(all_results, aes(x=noise,y=Kappa)) + geom_line(aes(colour=algorithm,group=algorithm)) + geom_point(aes(colour=algorithm),size=3)
@
<<plots_final, fig.width=8,fig.height=4,out.width='\\linewidth',results='hold',echo=FALSE, message=FALSE>>=
final_plot
@

\end{frame}
%------------------------------------------------

\begin{frame}[fragile]{Thanks}
\begin{center}
Thank you for your attention!\\
\begin{figure}
	\includegraphics[width=0.75\linewidth]{out_liar.jpg}
\end{figure}
\end{center}
\end{frame}
\begin{frame}[fragile]{Noise Sensitivity of ML algorithms (preliminary results)}
\Tiny
<<table_final,out.width='\\linewidth',echo=FALSE>>=
kable(all_results)
@

\end{frame}
%------------------------------------------------

\end{document}